<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>FaceGuard: AI Anonymizer</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&display=swap" rel="stylesheet">
  <style>
    :root {
      --primary-green: #10e956;
      --secondary-green: #05c541;
      --dark-bg: #0a1f12;
      --light-green: #2bff6c;
      --text-color: #e0ffe6;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Inter', sans-serif;
      background: linear-gradient(135deg, var(--dark-bg) 0%, #041a0a 100%);
      color: var(--text-color);
      min-height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
      overflow-x: hidden;
    }

    .container {
      background: rgba(16, 233, 86, 0.05);
      border: 2px solid var(--primary-green);
      border-radius: 20px;
      padding: 40px;
      width: 100%;
      max-width: 550px;
      box-shadow: 
        0 0 30px rgba(16, 233, 86, 0.2),
        0 0 60px rgba(16, 233, 86, 0.1);
      position: relative;
      overflow: hidden;
      transform: perspective(1000px);
      transition: all 0.5s ease;
    }

    .container::before {
      content: '';
      position: absolute;
      top: -50%;
      left: -50%;
      width: 200%;
      height: 200%;
      background: repeating-linear-gradient(
        transparent 0,
        transparent 7px,
        var(--primary-green) 10px,
        transparent 13px
      );
      animation: rotate 20s linear infinite;
      opacity: 0.1;
    }

    @keyframes rotate {
      100% {
        transform: rotate(360deg);
      }
    }

    .title {
      text-align: center;
      font-size: 2.2rem;
      margin-bottom: 30px;
      color: var(--light-green);
      text-transform: uppercase;
      letter-spacing: 2px;
      text-shadow: 0 0 10px rgba(16, 233, 86, 0.5);
      position: relative;
      animation: pulse 3s infinite alternate;
    }

    @keyframes pulse {
      0% { transform: scale(1); }
      100% { transform: scale(1.02); }
    }

    .control-section {
      display: flex;
      flex-direction: column;
      gap: 20px;
      margin-bottom: 30px;
    }

    .slider-container {
      display: flex;
      flex-direction: column;
      gap: 10px;
    }

    .slider-label {
      display: flex;
      justify-content: space-between;
      align-items: center;
      color: var(--light-green);
    }

    input[type="range"] {
      width: 100%;
      appearance: none;
      height: 10px;
      background: linear-gradient(to right, var(--secondary-green), var(--primary-green));
      border-radius: 5px;
      outline: none;
      opacity: 0.7;
      transition: opacity 0.2s;
    }

    input[type="range"]::-webkit-slider-thumb {
      appearance: none;
      width: 20px;
      height: 20px;
      background: var(--light-green);
      cursor: pointer;
      border-radius: 50%;
      box-shadow: 0 0 10px var(--primary-green);
    }

    .action-buttons {
      display: flex;
      justify-content: center;
      gap: 20px;
      flex-wrap: wrap;
    }

    .cyber-btn {
      background: var(--primary-green);
      color: var(--dark-bg);
      border: none;
      padding: 12px 25px;
      border-radius: 10px;
      cursor: pointer;
      font-weight: 600;
      text-transform: uppercase;
      letter-spacing: 1px;
      transition: all 0.3s ease;
      box-shadow: 0 0 15px rgba(16, 233, 86, 0.5);
    }

    .cyber-btn:hover {
      background: var(--light-green);
      transform: scale(1.05);
      box-shadow: 0 0 25px var(--light-green);
    }

    .cyber-btn:disabled {
      opacity: 0.5;
      cursor: not-allowed;
      transform: none;
    }

    .progress-container {
      margin-top: 20px;
      background: rgba(16, 233, 86, 0.1);
      border-radius: 10px;
      overflow: hidden;
    }

    .progress-bar {
      height: 10px;
      background: linear-gradient(to right, var(--primary-green), var(--light-green));
      width: 0%;
      transition: width 0.5s ease;
    }

    .stats-section {
      display: flex;
      justify-content: space-between;
      margin-top: 20px;
      color: var(--light-green);
      font-size: 0.9rem;
    }

    .loader {
      border: 4px solid rgba(16, 233, 86, 0.2);
      border-top: 4px solid var(--primary-green);
      border-radius: 50%;
      width: 50px;
      height: 50px;
      animation: spin 1s linear infinite;
      margin: 20px auto;
      display: none;
    }

    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }

    @media (max-width: 600px) {
      .container {
        margin: 20px;
        padding: 25px;
      }
      .title {
        font-size: 1.8rem;
      }
    }

    .file-input {
      display: none;
    }

    #outputCanvas {
      display: none;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1 class="title">FaceGuard: AI Anonymizer</h1>
    
    <div class="control-section">
      <div class="slider-container">
        <div class="slider-label">
          <span>Blur Intensity</span>
          <span id="blurValue">20</span>
        </div>
        <input type="range" id="blurStrength" min="5" max="50" value="20" />
      </div>
    </div>

    <div class="action-buttons">
      <label for="videoInput" class="cyber-btn">
        Upload Video
      </label>
      <input type="file" id="videoInput" class="file-input" accept="video/*" />
      <button id="downloadBtn" class="cyber-btn" disabled>Download Video</button>
    </div>

    <div class="loader" id="loader"></div>

    <div class="progress-container">
      <div class="progress-bar" id="progressBar"></div>
    </div>

    <div class="stats-section">
      <div>Processing: <span id="progress">0%</span></div>
      <div>Detected Faces: <span id="faceCount">0</span></div>
    </div>
  </div>

  <canvas id="outputCanvas"></canvas>

  <script>
    const videoInput = document.getElementById('videoInput');
    const downloadBtn = document.getElementById('downloadBtn');
    const progress = document.getElementById('progress');
    const faceCount = document.getElementById('faceCount');
    const loader = document.getElementById('loader');
    const blurStrength = document.getElementById('blurStrength');
    const blurValue = document.getElementById('blurValue');
    const progressBar = document.getElementById('progressBar');
    const outputCanvas = document.getElementById('outputCanvas');

    let model;
    let mediaRecorder;
    let recordedChunks = [];
    let processing = false;
    let currentBlur = 20;

    // Load Blazeface model
    async function loadModel() {
      loader.style.display = 'block';
      try {
        model = await blazeface.load();
        console.log("Model loaded successfully!");
        loader.style.display = 'none';
      } catch (error) {
        console.error("Model load failed:", error);
        alert("Error loading AI model. Please try again.");
        loader.style.display = 'none';
      }
    }
    loadModel();

    // Blur strength update
    blurStrength.addEventListener('input', () => {
      currentBlur = blurStrength.value;
      blurValue.textContent = currentBlur;
    });

    // Process video on upload
    videoInput.addEventListener('change', async () => {
      if (!model) {
        alert("AI model is not loaded yet. Please wait.");
        return;
      }
      
      const videoFile = videoInput.files[0];
      if (!videoFile) return;

      loader.style.display = 'block';
      downloadBtn.disabled = true;
      recordedChunks = [];

      const videoUrl = URL.createObjectURL(videoFile);
      const videoElement = document.createElement('video');
      videoElement.src = videoUrl;
      
      await new Promise(resolve => {
        videoElement.onloadedmetadata = resolve;
      });

      // Configure canvas
      outputCanvas.width = videoElement.videoWidth;
      outputCanvas.height = videoElement.videoHeight;
      const ctx = outputCanvas.getContext('2d');

      // Setup media recorder
      const canvasStream = outputCanvas.captureStream(30);
      mediaRecorder = new MediaRecorder(canvasStream, {
        mimeType: 'video/webm'
      });

      mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);
      mediaRecorder.onstop = () => {
        const blob = new Blob(recordedChunks, { type: 'video/webm' });
        const url = URL.createObjectURL(blob);
        
        const a = document.createElement('a');
        a.href = url;
        a.download = `anonymized-video-${Date.now()}.webm`;
        document.body.appendChild(a);
        a.click();
        URL.revokeObjectURL(url);
        
        downloadBtn.disabled = false;
      };

      mediaRecorder.start();

      // Start processing
      processing = true;
      const startTime = Date.now();
      const totalDuration = videoElement.duration * 1000;

      async function processFrame() {
        if (!processing) return;

        const currentTime = Date.now() - startTime;
        videoElement.currentTime = currentTime / 1000;
        
        await new Promise(resolve => {
          videoElement.onseeked = resolve;
        });

        ctx.drawImage(videoElement, 0, 0, outputCanvas.width, outputCanvas.height);

        // Face detection and blur
        const predictions = await model.estimateFaces(videoElement);
        faceCount.textContent = predictions.length;

        predictions.forEach(pred => {
          const [x, y, width, height] = [
            pred.topLeft[0],
            pred.topLeft[1],
            pred.bottomRight[0] - pred.topLeft[0],
            pred.bottomRight[1] - pred.topLeft[1]
          ];

          ctx.save();
          ctx.beginPath();
          ctx.rect(x, y, width, height);
          ctx.clip();
          ctx.filter = `blur(${currentBlur}px)`;
          ctx.drawImage(outputCanvas, x, y, width, height, x, y, width, height);
          ctx.restore();
        });

        // Update progress
        const progressPercent = (currentTime / totalDuration) * 100;
        progress.textContent = `${progressPercent.toFixed(1)}%`;
        progressBar.style.width = `${progressPercent}%`;

        if (currentTime < totalDuration) {
          requestAnimationFrame(processFrame);
        } else {
          stopProcessing();
        }
      }

      processFrame();
      loader.style.display = 'none';
    });

    function stopProcessing() {
      processing = false;
      mediaRecorder.stop();
    }

    // Download button event
    downloadBtn.addEventListener('click', () => {
      if (recordedChunks.length > 0) {
        const blob = new Blob(recordedChunks, { type: 'video/webm' });
        const url = URL.createObjectURL(blob);
        
        const a = document.createElement('a');
        a.href = url;
        a.download = `anonymized-video-${Date.now()}.webm`;
        document.body.appendChild(a);
        a.click();
        URL.revokeObjectURL(url);
      }
    });
  </script>
</body>
</html>
