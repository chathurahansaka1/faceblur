<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Auto Face Blur</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
  <style>
    :root {
      --primary-color: #00ff87;
      --background: #1a1a1a;
      --highlight-color: #00cc70;
    }
    body {
      margin: 0;
      padding: 10px;
      background: var(--background);
      color: #fff;
      font-family: 'Segoe UI', sans-serif;
    }
    .container {
      max-width: 800px;
      margin: auto;
      text-align: center;
      padding: 20px;
    }
    h1 {
      color: var(--primary-color);
    }
    .controls {
      margin: 15px 0;
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      justify-content: center;
    }
    button, .custom-file-upload {
      background: var(--primary-color);
      color: #000;
      border: none;
      padding: 10px 20px;
      cursor: pointer;
      border-radius: 8px;
      font-size: 14px;
      transition: transform 0.2s, background 0.3s;
    }
    button:hover, .custom-file-upload:hover {
      background: var(--highlight-color);
      transform: scale(1.05);
    }
    .progress-bar {
      width: 100%;
      height: 10px;
      background: rgba(255, 255, 255, 0.1);
      border-radius: 5px;
      margin: 20px auto;
      overflow: hidden;
    }
    .progress-bar-fill {
      height: 100%;
      background: var(--primary-color);
      width: 0%;
      transition: width 0.3s ease;
    }
    .stats {
      margin-top: 15px;
      font-size: 14px;
      color: #aaa;
    }
    #faceCount {
      color: var(--primary-color);
      font-weight: bold;
    }
    .loader {
      display: none;
      border: 4px solid #f3f3f3;
      border-top: 4px solid var(--primary-color);
      border-radius: 50%;
      width: 30px;
      height: 30px;
      animation: spin 1s linear infinite;
      margin: 10px auto;
    }
    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }
    /* The canvas is displayed responsively while its intrinsic resolution remains high */
    canvas {
      display: block;
      max-width: 100%;
      height: auto;
      margin: 20px auto;
      border: 2px solid var(--primary-color);
      border-radius: 8px;
    }
    @media (max-width: 600px) {
      .container {
        padding: 10px;
      }
      button, .custom-file-upload {
        padding: 8px 16px;
        font-size: 12px;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Auto Face Blur</h1>
    
    <div class="controls">
      <label for="videoInput" class="custom-file-upload">Upload Video</label>
      <input type="file" id="videoInput" accept="video/*" style="display: none;" />
      <button id="downloadBtn" disabled>Download Blurred Video</button>
    </div>
    
    <div class="progress-bar">
      <div class="progress-bar-fill" id="progressBar"></div>
    </div>
    
    <div class="stats">
      <div>Progress: <span id="progress">0%</span></div>
      <div>Detected Faces: <span id="faceCount">0</span></div>
      <div>Quality: Same as uploaded video</div>
    </div>
    
    <div class="loader" id="loader"></div>
    
    <!-- Canvas displaying the processed video -->
    <canvas id="outputCanvas"></canvas>
  </div>
  
  <script>
    const videoInput = document.getElementById('videoInput');
    const downloadBtn = document.getElementById('downloadBtn');
    const progress = document.getElementById('progress');
    const faceCount = document.getElementById('faceCount');
    const progressBar = document.getElementById('progressBar');
    const loader = document.getElementById('loader');
    const outputCanvas = document.getElementById('outputCanvas');
    const ctx = outputCanvas.getContext('2d');
    
    let model;
    let mediaRecorder;
    let recordedChunks = [];
    let processing = false;
    
    // Load the face detection model
    async function loadModel() {
      loader.style.display = 'block';
      try {
        model = await blazeface.load();
        console.log("Model loaded!");
      } catch (error) {
        console.error("Model load failed:", error);
        alert("Error loading model. Check console.");
      }
      loader.style.display = 'none';
    }
    loadModel();
    
    videoInput.addEventListener('change', async () => {
      if (!model) return alert("Model not loaded!");
      
      const videoFile = videoInput.files[0];
      if (!videoFile) return;
      
      loader.style.display = 'block';
      recordedChunks = []; // Clear previous recordings
      
      // Create a video element to load the file
      const videoUrl = URL.createObjectURL(videoFile);
      const videoElement = document.createElement('video');
      videoElement.src = videoUrl;
      videoElement.muted = false; // To capture audio
      videoElement.playsInline = true;
      videoElement.controls = true; // Optional: to see the video
      
      await new Promise(resolve => {
        videoElement.onloadedmetadata = resolve;
      });
      
      // Set canvas dimensions to match the uploaded video
      outputCanvas.width = videoElement.videoWidth;
      outputCanvas.height = videoElement.videoHeight;
      
      // Calculate a dynamic bitrate so that quality is maintained
      // Multiplier of 5 is chosen; adjust if needed for very high resolutions.
      const bitRate = videoElement.videoWidth * videoElement.videoHeight * 5;
      
      // Capture the canvas stream (which shows processed frames)
      const canvasStream = outputCanvas.captureStream(30);
      // Add audio track from the original video
      const audioTracks = videoElement.captureStream().getAudioTracks();
      if (audioTracks.length > 0) {
        canvasStream.addTrack(audioTracks[0]);
      }
      
      // Initialize MediaRecorder with the calculated bitrate
      try {
        mediaRecorder = new MediaRecorder(canvasStream, {
          mimeType: 'video/webm;codecs=vp9',
          videoBitsPerSecond: bitRate
        });
      } catch (e) {
        alert("MediaRecorder initialization failed: " + e);
        console.error(e);
        loader.style.display = 'none';
        return;
      }
      
      mediaRecorder.ondataavailable = e => {
        if (e.data.size > 0) {
          recordedChunks.push(e.data);
        }
      };
      
      mediaRecorder.onerror = e => {
        console.error("MediaRecorder error:", e);
        alert("Recording error occurred.");
      };
      
      mediaRecorder.onstop = () => {
        downloadBtn.disabled = false;
      };
      
      mediaRecorder.start(100);
      
      processing = true;
      const startTime = Date.now();
      const totalDuration = videoElement.duration * 1000;
      
      // Optionally play the video for viewing while processing
      videoElement.play();
      
      // Process frames: draw video frame on canvas and apply face blur
      (async function processFrame() {
        if (!processing) return;
        
        const currentTime = Date.now() - startTime;
        if (currentTime > totalDuration) {
          stopProcessing();
          return;
        }
        
        // Set current time and wait for seek to complete
        videoElement.currentTime = currentTime / 1000;
        await new Promise(resolve => {
          videoElement.onseeked = resolve;
        });
        
        // Draw the current video frame onto the canvas
        ctx.drawImage(videoElement, 0, 0, outputCanvas.width, outputCanvas.height);
        
        // Detect faces and apply a 20px blur to each detected region
        const predictions = await model.estimateFaces(videoElement);
        faceCount.textContent = predictions.length;
        predictions.forEach(pred => {
          const [x, y, width, height] = [
            pred.topLeft[0],
            pred.topLeft[1],
            pred.bottomRight[0] - pred.topLeft[0],
            pred.bottomRight[1] - pred.topLeft[1]
          ];
          ctx.save();
          ctx.beginPath();
          ctx.rect(x, y, width, height);
          ctx.clip();
          ctx.filter = 'blur(20px)';
          ctx.drawImage(outputCanvas, x, y, width, height, x, y, width, height);
          ctx.restore();
        });
        
        // Update progress display
        const progressPercent = (currentTime / totalDuration) * 100;
        progress.textContent = `${progressPercent.toFixed(1)}%`;
        progressBar.style.width = `${progressPercent}%`;
        
        requestAnimationFrame(processFrame);
      })();
      
      loader.style.display = 'none';
    });
    
    downloadBtn.addEventListener('click', () => {
      const blob = new Blob(recordedChunks, { type: 'video/webm' });
      const url = URL.createObjectURL(blob);
      const a = document.createElement('a');
      a.href = url;
      a.download = `blurred-video-${Date.now()}_HD.webm`;
      document.body.appendChild(a);
      a.click();
      URL.revokeObjectURL(url);
    });
    
    function stopProcessing() {
      processing = false;
      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
      }
    }
  </script>
</body>
</html>