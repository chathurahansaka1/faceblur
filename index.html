<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Face Blur</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <style>
        body { margin: 0; padding: 20px; background: #1a1a1a; color: #fff; }
        .container { max-width: 800px; margin: auto; }
        video, canvas { width: 100%; border: 2px solid #00ff87; border-radius: 8px; }
        .controls { margin: 20px 0; }
        button { background: #00ff87; color: #000; border: none; padding: 10px 20px; cursor: pointer; }
    </style>
</head>
<body>
    <div class="container">
        <video id="inputVideo" controls></video>
        <canvas id="outputCanvas"></canvas>
        <div class="controls">
            <input type="file" id="videoInput" accept="video/*">
            <button id="processBtn">Start Processing</button>
            <a id="downloadLink" hidden><button>Download MP4</button></a>
        </div>
    </div>

    <script>
        const videoInput = document.getElementById('videoInput');
        const inputVideo = document.getElementById('inputVideo');
        const outputCanvas = document.getElementById('outputCanvas');
        const processBtn = document.getElementById('processBtn');
        const downloadLink = document.getElementById('downloadLink');

        let model;
        let mediaRecorder;
        let recordedChunks = [];
        let isProcessing = false;

        // මාදිලිය පූරණය කිරීමේ දෝෂ අසාර්ථකත්වය හැසිරවීම
        async function loadModel() {
            try {
                model = await blazeface.load();
                console.log("Model loaded successfully!");
            } catch (error) {
                console.error("Model loading failed:", error);
                alert("මාදිලිය පූරණය කිරීම අසාර්ථක විය. අන්තර්ජාල සම්බන්ධතාවය පරීක්ෂා කරන්න.");
            }
        }
        loadModel();

        // වීඩියෝ ප්‍රමාණය සහ ධාරාව සකස් කිරීම
        videoInput.addEventListener('change', async (e) => {
            const file = e.target.files[0];
            const url = URL.createObjectURL(file);
            
            await new Promise((resolve) => {
                inputVideo.onloadedmetadata = () => {
                    outputCanvas.width = inputVideo.videoWidth;
                    outputCanvas.height = inputVideo.videoHeight;
                    resolve();
                };
                inputVideo.src = url;
            });
        });

        // ප්‍රක්‍රියාකාරක ලූපය
        async function processingLoop() {
            if (!isProcessing || inputVideo.paused || inputVideo.ended) {
                mediaRecorder?.stop();
                return;
            }

            await processFrame();
            requestAnimationFrame(processingLoop);
        }

        // රාමුව සැකසීම
        async function processFrame() {
            const ctx = outputCanvas.getContext('2d');
            
            ctx.drawImage(inputVideo, 0, 0, outputCanvas.width, outputCanvas.height);
            
            try {
                const predictions = await model.estimateFaces(inputVideo, false);
                
                predictions.forEach(prediction => {
                    const start = prediction.topLeft;
                    const end = prediction.bottomRight;
                    const width = end[0] - start[0];
                    const height = end[1] - start[1];

                    // බ්ලර් කිරීමේ කොටස
                    ctx.save();
                    ctx.beginPath();
                    ctx.rect(start[0], start[1], width, height);
                    ctx.clip();
                    ctx.filter = 'blur(20px)';
                    ctx.drawImage(outputCanvas, start[0], start[1], width, height, start[0], start[1], width, height);
                    ctx.restore();
                });
            } catch (error) {
                console.error("Face detection error:", error);
            }
        }

        // ප්‍රොසෙසින් ආරම්භ කිරීම
        processBtn.addEventListener('click', async () => {
            if (!model) {
                alert("මාදිලිය තවම පූරණය වී නැත!");
                return;
            }

            isProcessing = true;
            recordedChunks = [];
            
            // MediaRecorder සකස් කිරීම
            const stream = outputCanvas.captureStream(25);
            mediaRecorder = new MediaRecorder(stream, { 
                mimeType: 'video/webm;codecs=vp9',
                videoBitsPerSecond: 2500000 
            });

            mediaRecorder.ondataavailable = (e) => e.data.size > 0 && recordedChunks.push(e.data);
            mediaRecorder.onstop = () => {
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const url = URL.createObjectURL(blob);
                
                // WebM එක MP4 බවට පරිවර්තනය
                const ffmpeg = new FFmpeg();
                // FFmpeg.wasm භාවිතා කර පරිවර්තනය කිරීම අවශ්ය
                // (මෙම කොටස අමතර ක්රියාවලියක් අවශ්ය)
                
                downloadLink.href = url;
                downloadLink.download = `blurred-video-${Date.now()}.webm`;
                downloadLink.hidden = false;
            };

            mediaRecorder.start(100);
            inputVideo.play();
            processingLoop();
        });

        // පause තත්ත්වය හසුරුවීම
        inputVideo.addEventListener('pause', () => isProcessing = false);
        inputVideo.addEventListener('ended', () => isProcessing = false);
    </script>
</body>
</html>